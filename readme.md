# ğŸ§  AI Web Scraper & Parser

This Streamlit-powered app scrapes any public website, cleans and chunks its HTML content, and uses a locally hosted LLM (via Ollama) to extract targeted informationâ€”live, chunk-by-chunk.

---

## ğŸš€ Features

- ğŸ” Headless Web Scraping with Selenium  
- ğŸ§¼ DOM Cleaning & Chunking using BeautifulSoup  
- ğŸ§  LLM Parsing via LangChain + Ollama (Mistral model)  
- ğŸ“Š Real-Time Feedback with progress bar and live result rendering  
- âœ… Color-Coded Results for success, empty matches, and errors  
- ğŸ“ˆ Summary Metrics for total chunks, successful parses, and failures  
- ğŸ§­ Tabbed UI for scraping, chunk viewing, and parsing  
- ğŸ¨ Custom Styling with CSS and Google Fonts

---

## ğŸ› ï¸ Technologies

- Python, Streamlit, Selenium, BeautifulSoup  
- LangChain + Ollama  
- Modular architecture: `scrape.py`, `parse.py`, `main.py`

---

## ğŸ“¦ Installation

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Install Ollama locally
# Visit https://ollama.com/download and follow instructions for your OS
# Once installed, run:
ollama run mistral

# 3. Launch the app
streamlit run main.py
```
---

## ğŸ’¡ Note: 

This app uses the Mistral model via Ollama. You must have Ollama installed and running locally before parsing will work.
- https://ollama.com/download
- https://github.com/ollama/ollama
---

## ğŸ–¼ï¸ App Screenshot

![AI Web Scraper UI](assets/screenshot.png?raw=true "AI Web Scraper - Tabbed Interface with Dark Theme")

---

## ğŸ“‹ Usage

1. **Launch the app**  
   Run `streamlit run main.py` from your terminal.

2. **Scrape a website**  
   - Go to the **ğŸ” Scrape** tab  
   - Enter a valid URL (e.g. `https://en.uesp.net/wiki/Oblivion:Oblivion`)  
   - Toggle **headless mode** if desired  
   - Click **Scrape Site**

3. **View chunked content**  
   - Switch to the **ğŸ“„ View Chunks** tab  
   - Use **Previous/Next** buttons to navigate chunks  
   - Inspect each chunk in a scrollable text area

4. **Prepare for parsing**  
   - Go to the **ğŸ§  Parse with AI** tab  
   - Enter a description of what to extract  
   - Click **Parse Content** (LLM support coming soon)

---

## ğŸ“„ Example Parse Descriptions

- "The page title from the HTML"
- "Names of featured projects"
-"Any mention of awards or recognitions"

---

## ğŸ“Š Output Format

![AI Web Parser Screenshot](assets/ai-web-parser-screenshot-2.png?raw=true "AI Web Scraper - Tabbed Interface with Dark Theme")
Each chunk is parsed individually. Results are displayed live with:
- Output Type	Display Method:
- Valid Match	st.success() âœ…
- No Match Found	st.info() âš ï¸
- Parsing Error	st.error() âŒ

---

## ğŸ§  Prompt Template

Strict instructions ensure clean output:
- No commentary
- Empty string if no match
- Raw data onlyâ€”no formatting or labels

---

## ğŸ§¹ Cleanup & Resilience

![Real Time Terminal Output](assets/ai-web-parser-screenshot-3.png?raw=true "AI Web Scraper - Tabbed Interface with Dark Theme")
- Retry logic with timeout
- Fallback messages for empty/error chunks
- Scroll-to-results for smooth UX
- Chunk-by-chunk rendering for real-time feedback

---

## ğŸ› ï¸ Tech Stack

- Python 3.11+
- Streamlit
- Selenium
- BeautifulSoup
- Custom CSS (`styles/app.css`)

---

## ğŸ“ File Structure

<details>
<summary>ğŸ“ Click to view folder structure</summary>

```plaintext
AI-WEBSCRAPER/
â”œâ”€â”€ __pycache__/                 # Compiled Python cache files
â”‚   â”œâ”€â”€ parse.cpython-312.pyc
â”‚   â””â”€â”€ scrape.cpython-312.pyc
â”œâ”€â”€ ai/                          # Optional virtual environment (if used)
â”‚   â”œâ”€â”€ Include/
â”‚   â”œâ”€â”€ Lib/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â””â”€â”€ pyvenv.cfg
â”œâ”€â”€ assets/                      # Screenshots and media for documentation
â”œâ”€â”€ styles/
â”‚   â””â”€â”€ app.css                  # Custom CSS for Streamlit UI
â”œâ”€â”€ venv/                        # Python virtual environment
â”‚   â”œâ”€â”€ Include/
â”‚   â”œâ”€â”€ Lib/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â”œâ”€â”€ etc/
â”‚   â”œâ”€â”€ share/
â”‚   â””â”€â”€ pyvenv.cfg
â”œâ”€â”€ chromedriver.exe            # Chrome WebDriver for Selenium
â”œâ”€â”€ main.py                     # Streamlit app entry point
â”œâ”€â”€ parse.py                    # LLM parsing logic via LangChain + Ollama
â”œâ”€â”€ scrape.py                   # Web scraping and DOM chunking logic
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ readme.md                   # Project documentation
```
</details>

---

## ğŸ§ª Troubleshooting

If parsing fails or hangs:
```Bash
ollama list
```

You should see mistral listed and active. If not, run:

```Bash
ollama run mistral
```

---

## ğŸ“œ License

MIT License â€” feel free to fork, remix, and build on it.

---

## ğŸ™Œ Acknowledgments

Thanks to the open-source tools and libraries that make this possible. Stay tuned for LLM-powered parsing and more UX enhancements.